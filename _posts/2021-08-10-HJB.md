---
title: 'HJB Equation'
date: 2021-08-10
permalink: /posts/2021/08/HJB/
tags:
  - Physics
---
<!-- MathJax -->
<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<h1 id="classical-mechanics">Classical mechanics</h1>
<p>In Lagrangian formalism, we define an action functional S as follows: <span class="math display">\[\begin{aligned}
    S[q(t)]=\int_0^{\infty}L(q(t),\dot q(t),t) dt\end{aligned}\]</span> We vary <span class="math inline">\(q(t)\)</span> to obtain the minimum of action. We call the action corresponding to the minimum of the action, the Hamilton principal function. Then, <span class="math display">\[\begin{aligned}
    L=\frac{dS}{dt}&amp;=\frac{\partial S}{\partial t}+\frac{\partial S}{\partial x}\dot x\end{aligned}\]</span> Using the definition of Hamiltonian, <span class="math inline">\(H=p\dot x-L\)</span>, we get the Hamilton-Jacobi equation <span class="math display">\[\begin{aligned}
\frac{\partial S}{\partial t}+\frac{\partial S}{\partial x}\dot x-L&amp;=0\\
\frac{\partial S}{\partial t}+H(x,\frac{\partial S}{\partial x})&amp;=0\end{aligned}\]</span></p>
<h1 id="control-theory">Control Theory</h1>
<p>Is this correct: value function is time reversed Hamilton principal function? Also, the is difference between Hamilton principal function and action is that one is function corresponding to the optimal path while the latter is a functional? We call the Hamilton principal function, the value function and the Lagrangian, the cost rate function. So, <span class="math display">\[\begin{aligned}
    C=\frac{dV}{dt}&amp;=\frac{\partial V}{\partial t}+\frac{\partial V}{\partial x}\dot x \\
    &amp;=\frac{\partial V}{\partial t}+\frac{\partial V}{\partial x}F(x,u)\end{aligned}\]</span> <span class="math display">\[\begin{aligned}
    V(x(t),t)&amp;=V(x(t+dt),t+dt)+\int_{t}^{t+dt}C(x(s),u(s))du\\
     &amp;=V(x(t),t)+\frac{\partial V}{\partial t}dt+\frac{\partial V}{\partial x}\dot x d t+C(x(t),u(t))dt\end{aligned}\]</span> This give HJB, <span class="math display">\[\begin{aligned}
\frac{\partial V}{\partial t}+\frac{\partial V}{\partial x}F +C(x(t),u(t))=0\end{aligned}\]</span> So, <span class="math display">\[\begin{aligned}
\frac{\partial V}{\partial t}-H(x,u,-\frac{\partial V}{\partial x})=0\end{aligned}\]</span></p>
<h1 id="reinforcement-learning">Reinforcement Learning</h1>
<p>Maybe I need to consider stochastic version of the above equation to get the full Bellman equation. <span class="math display">\[\begin{aligned}
    v(s)=[r+v(s&#39;)]\end{aligned}\]</span></p>
